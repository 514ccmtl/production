{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../src/.env\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "ft_file = os.getenv(\"CREDIT_DATA\")\n",
    "df_raw = pd.read_csv(ft_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "\n",
    "+ For this example, we will use [Give Me Some Credit from Kaggle](https://www.kaggle.com/c/GiveMeSomeCredit/data), a widely refered example.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "+ To engineer features is to transform the data in such a way that the information content is easily exposed to the model.\n",
    "+ This statement can mean many things and highly depends on what exactly is \"the model\".\n",
    "+ A flexible approach is to think of composable transformation pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Transforms in sklearn\n",
    "\n",
    "Work with categorical variables:\n",
    "\n",
    "+ `preprocessing.Binarizer(*[, threshold, copy])`: Binarize data (set feature values to 0 or 1) according to a threshold.\n",
    "+ `preprocessing.KBinsDiscretizer([n_bins, ...])`:  Bin continuous data into intervals.\n",
    "+ `preprocessing.LabelBinarizer(*[, neg_label, ...])`: Binarize labels in a one-vs-all fashion.\n",
    "+ `preprocessing.LabelEncoder()`: Encode target labels with value between 0 and n_classes-1.\n",
    "+ `preprocessing.MultiLabelBinarizer(*[, ...])`:  Transform between iterable of iterables and a multilabel format.\n",
    "+ `preprocessing.OneHotEncoder(*[, categories, ...])`: Encode categorical features as a one-hot numeric array.\n",
    "+ `preprocessing.OrdinalEncoder(*[, ...])`: Encode categorical features as an integer array.\n",
    "\n",
    "Scale and normalize:\n",
    "\n",
    "+ `preprocessing.StandardScaler(*[, copy, ...])`: Standardize features by removing the mean and scaling to unit variance.\n",
    "+ `preprocessing.MaxAbsScaler(*[, copy])`: Scale each feature by its maximum absolute value.\n",
    "+ `preprocessing.MinMaxScaler([feature_range, ...])`: Transform features by scaling each feature to a given range.\n",
    "+ `preprocessing.Normalizer([norm, copy])`:  Normalize samples individually to unit norm.\n",
    "+ `preprocessing.RobustScaler(*[, ...])`: Scale features using statistics that are robust to outliers.\n",
    "\n",
    "\n",
    "Nonlinear transforms:\n",
    "\n",
    "+ `preprocessing.FunctionTransformer([func, ...])`: Constructs a transformer from an arbitrary callable.\n",
    "+ `preprocessing.KernelCenterer()`: Center an arbitrary kernel matrix \n",
    "+ `preprocessing.PolynomialFeatures([degree, ...])`: Generate polynomial and interaction features.\n",
    "+ `preprocessing.PowerTransformer([method, ...])`: Apply a power transform featurewise to make data more Gaussian-like.\n",
    "+ `preprocessing.QuantileTransformer(*[, ...])`: Transform features using quantiles information.\n",
    "+ `preprocessing.SplineTransformer([n_knots, ...])`: Generate univariate B-spline bases for features.\n",
    "+ `preprocessing.TargetEncoder([categories, ...])`: Target Encoder for regression and classification targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we doing?\n",
    "\n",
    "![](./img/column_transform_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   Unnamed: 0                            150000 non-null  int64  \n",
      " 1   SeriousDlqin2yrs                      150000 non-null  int64  \n",
      " 2   RevolvingUtilizationOfUnsecuredLines  150000 non-null  float64\n",
      " 3   age                                   150000 non-null  int64  \n",
      " 4   NumberOfTime30-59DaysPastDueNotWorse  150000 non-null  int64  \n",
      " 5   DebtRatio                             150000 non-null  float64\n",
      " 6   MonthlyIncome                         120269 non-null  float64\n",
      " 7   NumberOfOpenCreditLinesAndLoans       150000 non-null  int64  \n",
      " 8   NumberOfTimes90DaysLate               150000 non-null  int64  \n",
      " 9   NumberRealEstateLoansOrLines          150000 non-null  int64  \n",
      " 10  NumberOfTime60-89DaysPastDueNotWorse  150000 non-null  int64  \n",
      " 11  NumberOfDependents                    146076 non-null  float64\n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 13.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform in pandas or sklearn?\n",
    "\n",
    "+ Depending on the perspective, the answer could be neither, pandas, or sklearn:\n",
    "\n",
    "    - Neither: most join and filtering should be done closer to the source using a database or parquet/Dask operation. \n",
    "    - Pandas, Dask, or PySpark: \n",
    "        * Renames and management tasks.\n",
    "        * Use python libraries like pandas, Dask, or pySpark to add contemporaneous feature, time-series manipulation (for example, adding lags), parallel computation (using Dask or pySpark).\n",
    "        * Do not use these libraries for sample-dependent features.\n",
    "    - Use sklearn, pytorch:\n",
    "        * Use python libraries like sklearn or pytorch to add features that are sample-dependent like scaling and normalization, one-hot encoding, tokenization, and vectorization.\n",
    "        * Model-depdenent transformations: PCA, embeddings, etc.\n",
    "        \n",
    "+ Decisions must be guided by optimization criteria (time and resources) while avoiding data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.drop(columns = [\"Unnamed: 0\"]).rename(\n",
    "    columns = {\n",
    "        'SeriousDlqin2yrs': 'delinquency',\n",
    "        'RevolvingUtilizationOfUnsecuredLines': 'revolving_unsecured_line_utilization', \n",
    "        'age': 'age',\n",
    "        'NumberOfTime30-59DaysPastDueNotWorse': 'num_30_59_days_late', \n",
    "        'DebtRatio': 'debt_ratio', \n",
    "        'MonthlyIncome': 'monthly_income',\n",
    "        'NumberOfOpenCreditLinesAndLoans': 'num_open_credit_loans', \n",
    "        'NumberOfTimes90DaysLate':  'num_90_days_late',\n",
    "        'NumberRealEstateLoansOrLines': 'num_real_estate_loans', \n",
    "        'NumberOfTime60-89DaysPastDueNotWorse': 'num_60_89_days_late',\n",
    "        'NumberOfDependents': 'num_dependents'\n",
    "    }\n",
    ").assign(\n",
    "    high_debt_ratio = lambda x: x['debt_ratio'] > 1, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline that: \n",
    "\n",
    "+ Standardizes numerical features.\n",
    "+ Applies one-hot encoding to sector.\n",
    "+ Tokenizes subsector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delinquency</th>\n",
       "      <th>revolving_unsecured_line_utilization</th>\n",
       "      <th>age</th>\n",
       "      <th>num_30_59_days_late</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>num_open_credit_loans</th>\n",
       "      <th>num_90_days_late</th>\n",
       "      <th>num_real_estate_loans</th>\n",
       "      <th>num_60_89_days_late</th>\n",
       "      <th>num_dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.305682</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116951</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2058.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.392248</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.595253</td>\n",
       "      <td>4676.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149976</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149977</th>\n",
       "      <td>0</td>\n",
       "      <td>0.236450</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149984</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037548</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149992</th>\n",
       "      <td>0</td>\n",
       "      <td>0.871976</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.246044</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35137 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        delinquency  revolving_unsecured_line_utilization  age  \\\n",
       "6                 0                              0.305682   57   \n",
       "8                 0                              0.116951   27   \n",
       "14                0                              0.019657   76   \n",
       "16                0                              0.061086   78   \n",
       "25                1                              0.392248   50   \n",
       "...             ...                                   ...  ...   \n",
       "149976            0                              0.000627   76   \n",
       "149977            0                              0.236450   29   \n",
       "149984            0                              0.037548   84   \n",
       "149992            0                              0.871976   50   \n",
       "149997            0                              0.246044   58   \n",
       "\n",
       "        num_30_59_days_late   debt_ratio  monthly_income  \\\n",
       "6                         0  5710.000000             NaN   \n",
       "8                         0    46.000000             NaN   \n",
       "14                        0   477.000000             0.0   \n",
       "16                        0  2058.000000             NaN   \n",
       "25                        0     1.595253          4676.0   \n",
       "...                     ...          ...             ...   \n",
       "149976                    0    60.000000             NaN   \n",
       "149977                    0   349.000000             NaN   \n",
       "149984                    0    25.000000             NaN   \n",
       "149992                    0  4132.000000             NaN   \n",
       "149997                    0  3870.000000             NaN   \n",
       "\n",
       "        num_open_credit_loans  num_90_days_late  num_real_estate_loans  \\\n",
       "6                           8                 0                      3   \n",
       "8                           2                 0                      0   \n",
       "14                          6                 0                      1   \n",
       "16                         10                 0                      2   \n",
       "25                         14                 0                      3   \n",
       "...                       ...               ...                    ...   \n",
       "149976                      5                 0                      0   \n",
       "149977                      3                 0                      0   \n",
       "149984                      5                 0                      0   \n",
       "149992                     11                 0                      1   \n",
       "149997                     18                 0                      1   \n",
       "\n",
       "        num_60_89_days_late  num_dependents  \n",
       "6                         0             0.0  \n",
       "8                         0             NaN  \n",
       "14                        0             0.0  \n",
       "16                        0             0.0  \n",
       "25                        0             1.0  \n",
       "...                     ...             ...  \n",
       "149976                    0             0.0  \n",
       "149977                    0             0.0  \n",
       "149984                    0             0.0  \n",
       "149992                    0             3.0  \n",
       "149997                    0             0.0  \n",
       "\n",
       "[35137 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['debt_ratio'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_num = Pipeline([\n",
    "    ('standardizer', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector Encoding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "pipe_onehot = Pipeline([\n",
    "    ('one_hot', OneHotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsector Feature Extraction \n",
    "\n",
    "+ In the case of `subsector`, we have a variable with 124 entries. \n",
    "+ We would like to tokenize each entry and transform the tokenized representation into one-hot encoding.\n",
    "+ To tokenize, is to transform a string into smaller components. For example, phrases into individual words.\n",
    "+ To achieve this, we can use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Telecom Tower REITs',\n",
       " 'Semiconductors',\n",
       " 'Multi-Utilities',\n",
       " 'Managed Health Care',\n",
       " 'Biotechnology',\n",
       " 'Multi-Family Residential REITs',\n",
       " 'Automobile Manufacturers',\n",
       " 'Consumer Staples Merchandise Retail',\n",
       " 'Electronic Equipment & Instruments',\n",
       " 'Electric Utilities',\n",
       " 'Health Care Services',\n",
       " 'Investment Banking & Brokerage',\n",
       " 'Health Care Equipment',\n",
       " 'Technology Hardware, Storage & Peripherals',\n",
       " 'Food Distributors',\n",
       " 'Regional Banks',\n",
       " 'Semiconductor Materials & Equipment',\n",
       " 'Broadcasting',\n",
       " 'Retail REITs',\n",
       " 'Restaurants',\n",
       " 'Passenger Airlines',\n",
       " 'Air Freight & Logistics',\n",
       " 'Oil & Gas Equipment & Services',\n",
       " 'Life & Health Insurance',\n",
       " 'Movies & Entertainment',\n",
       " 'Building Products',\n",
       " 'Electrical Components & Equipment',\n",
       " 'Copper',\n",
       " 'Paper & Plastic Packaging Products & Materials',\n",
       " 'Hotels, Resorts & Cruise Lines',\n",
       " 'Personal Care Products',\n",
       " 'Asset Management & Custody Banks',\n",
       " 'Industrial Conglomerates',\n",
       " 'Electronic Components',\n",
       " 'Financial Exchanges & Data',\n",
       " 'IT Consulting & Other Services',\n",
       " 'Industrial Machinery & Supplies & Components',\n",
       " 'Industrial Gases',\n",
       " 'Commodity Chemicals',\n",
       " 'Health Care REITs',\n",
       " 'Apparel, Accessories & Luxury Goods',\n",
       " 'Integrated Oil & Gas',\n",
       " 'Application Software',\n",
       " 'Construction Materials',\n",
       " 'Transaction & Payment Processing Services',\n",
       " 'Interactive Media & Services',\n",
       " 'Property & Casualty Insurance',\n",
       " 'Data Center REITs',\n",
       " 'Human Resource & Employment Services',\n",
       " 'Consumer Finance',\n",
       " 'Independent Power Producers & Energy Traders',\n",
       " 'Life Sciences Tools & Services',\n",
       " 'Other Specialty Retail',\n",
       " 'Specialty Chemicals',\n",
       " 'Packaged Foods & Meats',\n",
       " 'Health Care Supplies',\n",
       " 'Construction Machinery & Heavy Transportation Equipment',\n",
       " 'Aerospace & Defense',\n",
       " 'Internet Services & Infrastructure',\n",
       " 'Health Care Facilities',\n",
       " 'Cable & Satellite',\n",
       " 'Health Care Distributors',\n",
       " 'Single-Family Residential REITs',\n",
       " 'Self-Storage REITs',\n",
       " 'Homebuilding',\n",
       " 'Broadline Retail',\n",
       " 'Hotel & Resort REITs',\n",
       " 'Insurance Brokers',\n",
       " 'Office REITs',\n",
       " 'Integrated Telecommunication Services',\n",
       " 'Oil & Gas Exploration & Production',\n",
       " 'Home Furnishings',\n",
       " 'Environmental & Facilities Services',\n",
       " 'Household Products',\n",
       " 'Distributors',\n",
       " 'Pharmaceuticals',\n",
       " 'Interactive Home Entertainment',\n",
       " 'Electronic Manufacturing Services',\n",
       " 'Oil & Gas Storage & Transportation',\n",
       " 'Oil & Gas Refining & Marketing',\n",
       " 'Steel',\n",
       " 'Diversified Banks',\n",
       " 'Diversified Support Services',\n",
       " 'Agricultural Products & Services',\n",
       " 'Computer & Electronics Retail',\n",
       " 'Tobacco',\n",
       " 'Industrial REITs',\n",
       " 'Publishing',\n",
       " 'Leisure Products',\n",
       " 'Multi-line Insurance',\n",
       " 'Food Retail',\n",
       " 'Soft Drinks & Non-alcoholic Beverages',\n",
       " 'Fertilizers & Agricultural Chemicals',\n",
       " 'Systems Software',\n",
       " 'Research & Consulting Services',\n",
       " 'Communications Equipment',\n",
       " 'Home Improvement Retail',\n",
       " 'Rail Transportation',\n",
       " 'Consumer Electronics',\n",
       " 'Cargo Ground Transportation',\n",
       " 'Apparel Retail',\n",
       " 'Automotive Parts & Equipment',\n",
       " 'Other Specialized REITs',\n",
       " 'Trading Companies & Distributors',\n",
       " 'Technology Distributors',\n",
       " 'Water Utilities',\n",
       " 'Casinos & Gaming',\n",
       " 'Timber REITs',\n",
       " 'Automotive Retail',\n",
       " 'Construction & Engineering',\n",
       " 'Gas Utilities',\n",
       " 'Reinsurance',\n",
       " 'Advertising',\n",
       " 'Real Estate Services',\n",
       " 'Drug Retail',\n",
       " 'Agricultural & Farm Machinery',\n",
       " 'Data Processing & Outsourced Services',\n",
       " 'Distillers & Vintners',\n",
       " 'Brewers',\n",
       " 'Gold',\n",
       " 'Household Appliances',\n",
       " 'Wireless Telecommunication Services',\n",
       " 'Passenger Ground Transportation',\n",
       " 'Metal, Glass & Plastic Containers']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subsector'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04612762, -0.06840328,  3.04755527, ..., -0.37409732,\n",
       "        -0.20186597, -0.04845659],\n",
       "       [-0.28838193,  0.12201217,  0.14000315, ..., -0.37409732,\n",
       "        -0.20277346, -0.12272273],\n",
       "       [-0.32875765,  0.01622581, -0.37291337, ..., -0.37293476,\n",
       "        -0.1950787 , -0.02171777],\n",
       "       ...,\n",
       "       [ 1.84777221,  0.22866631, -0.76119768, ...,  5.82848849,\n",
       "        -0.19516693, -0.01063677],\n",
       "       [ 3.20438058,  4.82231501, -0.48342918, ...,  5.87895946,\n",
       "        -0.19266503,  0.02073887],\n",
       "       [ 3.0428777 ,  4.83586889, -0.52407759, ...,  5.9386689 ,\n",
       "        -0.1917922 ,  0.01320264]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
